{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data_point: float=None, data_list: list=None) -> float:\n",
    "    ''' Normalize the data to be within the rang of 0.0-1.0\n",
    "        Round answer to 2 digits\n",
    "    '''\n",
    "    \n",
    "    if not isinstance(data_point, (int, float)):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': Data point/value was not passed.\")\n",
    "    elif not isinstance(data_list, (list)):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': Data list of values was not passed.\")\n",
    "    else:\n",
    "        #return round( (data_point-min(data_list)) / (max(data_list)-min(data_list)), 2)\n",
    "        return format((data_point-min(data_list)) / (max(data_list)-min(data_list)), '0.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_topcs_methods(methods_list: list=None, topics_list: list=None):\n",
    "    \n",
    "    ### Try to collect all unique entries for methods and topics from reviewers\n",
    "    #print(f'All possible topics: {set(reviewer_topic_list)}')\n",
    "    \n",
    "    methods = []\n",
    "    #methods = set(methods_list)\n",
    "    uniq_methods = ', '.join(set(methods_list)).split(', ') \n",
    "    #print(f'All possible methods: {set(uniq_methods)}\\n')\n",
    "\n",
    "    topics = []\n",
    "    #topics = set(topics_list)\n",
    "    uniq_topics = ', '.join(set(topics_list)).split(', ') \n",
    "    #print(f'All possible topics: {set(uniq_topics)}\\n')\n",
    "\n",
    "    counter=0\n",
    "    #print(topics_list)\n",
    "    for topic in uniq_topics:\n",
    "        for t in topics_list:\n",
    "            if topic == t:\n",
    "                counter += 1\n",
    "        #print(f'{topic}: {counter}')\n",
    "    revi_methods = pd.DataFrame(data={'Methods': sorted(list(set(uniq_methods)))})\n",
    "    revi_methods.to_csv('reviewer_methods.csv', sep=';', index=False)\n",
    "    revi_topics = pd.DataFrame(data={'Methods': sorted(list(set(uniq_topics)))})\n",
    "    revi_topics.to_csv('reviewer_topics.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_top(candidates: pd.DataFrame=None, matching_df: pd.DataFrame=None) -> pd.DataFrame:\n",
    "    ''' Select the top 3 matchings for each candidate and reviewer and return the results.'''\n",
    "    \n",
    "    if not isinstance(candidates, pd.core.frame.DataFrame) or not isinstance(matching_df, pd.core.frame.DataFrame):\n",
    "        sys.exit(f\"Function '{filter_top.__name__}': Either 'candidates' or 'matching_df' \"\n",
    "                  \"was not passed as a Pandas dataframe.\")\n",
    "\n",
    "    reviewer_collector = {}\n",
    "    candidate_collector = {}\n",
    "    perfect_score_list = []\n",
    "\n",
    "    ## TODO: check to see if I can remove the second condition below (and...)\n",
    "\n",
    "    ## len(candidates) is the same as candidates.shape[0]\n",
    "\n",
    "    ## assign starting value of zero\n",
    "    for candidate in candidates.itertuples():\n",
    "        if not candidate[1] in candidate_collector and len(candidate_collector) < len(candidates):\n",
    "            candidate_collector[candidate[1]] = 0\n",
    "            #print(candidate_collector)\n",
    "\n",
    "    # key part: must operate on matching_df that has been sorted by total_score, and then limit it\n",
    "    for reviewer in matching_df.itertuples():\n",
    "        if not reviewer[1] in reviewer_collector and len(reviewer_collector) < len(candidates):\n",
    "            reviewer_collector[reviewer[1]] = 0\n",
    "            #print(reviewer_collector)\n",
    "\n",
    "    for index, matching_pair in matching_df.iterrows():\n",
    "        revi = matching_pair['reviewer']\n",
    "        revi_email = matching_pair['reviewer_email']\n",
    "        revi_topics = matching_pair['reviewer_topics']\n",
    "        revi_methods = matching_pair['reviewer_methods']\n",
    "        candi = matching_pair['candidate']\n",
    "        candi_email = matching_pair['candidate_email']\n",
    "        candi_topics = matching_pair['candidate_topics']\n",
    "        candi_methods = matching_pair['candidate_methods']\n",
    "        itimized_score = matching_pair['itimized_score_topics_methods_history']\n",
    "        total_score = matching_pair['total_score']\n",
    "        \n",
    "        if revi in reviewer_collector and candi in candidate_collector \\\n",
    "                                      and reviewer_collector[revi] != 3 \\\n",
    "                                      and candidate_collector[candi] != 3:\n",
    "            perfect_score_list.append((revi, candi, itimized_score, total_score))\n",
    "            reviewer_collector[revi] += 1\n",
    "            candidate_collector[candi] += 1\n",
    "            #print(reviewer_collector)\n",
    "\n",
    "    final_df = pd.DataFrame(data={'Reviewer Name': [i[0] for i in perfect_score_list],\n",
    "                                  'Candidate Name': [i[1] for i in perfect_score_list],\n",
    "                                  \"Itimized score [topics, methods, reviewer's history]\": [i[2] for i in perfect_score_list],\n",
    "                                  'total_score': [i[3] for i in perfect_score_list]})\n",
    "\n",
    "    # Could sort by \"Reviewer Name\" or \"Candidate Name\"\n",
    "    final_df = final_df.sort_values(by=['Candidate Name', 'total_score'], ascending=[True, False])\n",
    "    #final_df = final_df.sort_values(by=['total_score', 'Candidate Name'], ascending=[False, False])\n",
    "\n",
    "    #print(perfect_score_list)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(reviewer: pd.Series=None, candidate: pd.Series=None, reviewer_history: list=None) -> int:\n",
    "    ''' Score the matching between reviewer and candidate based on:\n",
    "        1) topics,\n",
    "        2) methods, and\n",
    "        3) history of recent reviews done by reviewer.\n",
    "    '''\n",
    "\n",
    "    if not isinstance(reviewer, pd.core.series.Series) or not isinstance(candidate, pd.core.series.Series):\n",
    "        sys.exit(f\"Function '{scoring.__name__}': Either 'reviewer' or 'candidate' \"\n",
    "                  \"was not passed as a Pandas dataframe.\")\n",
    "    elif not isinstance(reviewer_history, list):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': History of reviewers' reviews not passed.\")\n",
    "\n",
    "    score_topics = 0\n",
    "    score_methods = 0\n",
    "    score_history = 0\n",
    "    score_total = 0\n",
    "\n",
    "    reviewer_topics = reviewer['Topics'].split(sep=', ')\n",
    "    candidate_topics = candidate['Topics'].split(sep=', ')\n",
    "    reviewer_methods = reviewer['Methods'].split(sep=', ')\n",
    "    candidate_methods = candidate['Methods'].split(sep=', ')\n",
    "    \n",
    "    for topic in reviewer_topics:\n",
    "        if topic.lower() in candidate_topics:\n",
    "            score_topics += 1\n",
    "\n",
    "    for methodology in reviewer_methods:\n",
    "        if methodology in candidate_methods:\n",
    "            score_methods += 1\n",
    "\n",
    "    reviewer_history_reversed = list(reversed(reviewer_history))\n",
    "    \n",
    "    for session in reviewer_history_reversed:\n",
    "        #print(session, reviewer_history_reversed.index(session),\n",
    "        #      reviewer_history_reversed.index(session)+1, (reviewer_history_reversed.index(session)+1)/4)\n",
    "        factor = (reviewer_history_reversed.index(session)+1)/len(reviewer_history_reversed)\n",
    "        if str(reviewer[session]).lower() != 'reviewed':\n",
    "             score_history += (1 - factor)\n",
    "             #print(session, factor, score_history)\n",
    "\n",
    "    return score_topics, score_methods, score_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function annotation\n",
    "def perform_matching(reviewers: pd.DataFrame=None, candidates: pd.DataFrame=None,\n",
    "                     reviewer_history: list=None) -> pd.DataFrame:\n",
    "    '''\n",
    "    1. Creates lists from dataframes\n",
    "    2. Calls scoring function\n",
    "    3. Sorts the top 3 scoreed matches for each pairing\n",
    "    '''\n",
    "\n",
    "    if not isinstance(reviewers, pd.core.frame.DataFrame) or not isinstance(candidates, pd.core.frame.DataFrame):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': Either 'reviewers' or 'candidates' \"\n",
    "                 \"was not passed as a Pandas dataframe.\")\n",
    "    elif not isinstance(reviewer_history, list):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': History of reviewers' reviews not passed.\")\n",
    "\n",
    "    reviewer_name_list = []\n",
    "    reviewer_email_list = []\n",
    "    reviewer_topic_list = []\n",
    "    reviewer_method_list = []\n",
    "\n",
    "    candidate_name_list = []\n",
    "    candidate_email_list = []\n",
    "    candidate_topic_list = []\n",
    "    candidate_method_list = []\n",
    "\n",
    "    match_scoring_list = []\n",
    "\n",
    "    score_all_list = []\n",
    "    score_total_list = []\n",
    "\n",
    "    # Basic idea here is that each of the X reviewers is listed with each of the Y candidate, and then scored\n",
    "\n",
    "    for i in range(len(reviewers)):  # number_reviewers_rows; reviewers.shape[0]\n",
    "        for j in range(len(candidates)):  # number_candidates_rows; candidates.shape[0]\n",
    "            reviewer_name_list.append(reviewers.loc[i].Name)\n",
    "            reviewer_email_list.append(reviewers.loc[i].Email)\n",
    "            reviewer_topic_list.append(reviewers.loc[i].Topics)\n",
    "            reviewer_method_list.append(reviewers.loc[i].Methods)\n",
    "\n",
    "            candidate_name_list.append(candidates.loc[j].Name)\n",
    "            candidate_email_list.append(candidates.loc[j].Email)\n",
    "            candidate_topic_list.append(candidates.loc[j].Topics)\n",
    "            candidate_method_list.append(candidates.loc[j].Methods)\n",
    "\n",
    "            #print(reviewer_topic_list)\n",
    "            ## scoring is done here\n",
    "            score_topics, score_methods, score_history = scoring(reviewer=reviewers.loc[i], candidate=candidates.loc[j],\n",
    "                                             reviewer_history=reviewer_history)\n",
    "            score_all = [score_topics, score_methods, score_history]\n",
    "            score_all_list.append(score_all)\n",
    "\n",
    "            score_total = score_topics + score_methods + score_history\n",
    "            score_total_list.append(score_total)\n",
    "            #match_scoring_list.append(scoring(reviewer=reviewers.loc[i], candidate=candidates.loc[j]))\n",
    "    #print(score_all_list)\n",
    "    ##############\n",
    "    ## Normalizing attempt (history = 2)\n",
    "    top = []\n",
    "    sub = []\n",
    "    hist = []\n",
    "    \n",
    "    for sublist in (score_all_list):\n",
    "        top.append(sublist[0])\n",
    "        sub.append(sublist[1])\n",
    "        hist.append(sublist[2])\n",
    "    score_topic_normalized = [normalize(x, top) for x in top]\n",
    "    score_subject_normalized = [normalize(x, sub) for x in sub]\n",
    "    score_history_normalized = [normalize(x, hist) for x in hist]\n",
    "\n",
    "    score_all_list =[]\n",
    "    score_all_list.extend([list(a) for a in zip(score_topic_normalized,\n",
    "                                                       score_subject_normalized,\n",
    "                                                       score_history_normalized)])\n",
    "    #print(score_all_list)\n",
    "\n",
    "    score_total_list =[]\n",
    "    score_total_list =[float(a)+float(b)+float(c) for a,b,c in zip(score_topic_normalized,\n",
    "                                                       score_subject_normalized,\n",
    "                                                       score_history_normalized)]\n",
    "    #matching_df['itimized_score_topics_methods_history'] = hist_normalized\n",
    "    ##############\n",
    "    \n",
    "    results = {'reviewer': reviewer_name_list,\n",
    "               'reviewer_email': reviewer_email_list,\n",
    "               'reviewer_topics': reviewer_topic_list,\n",
    "               'reviewer_methods': reviewer_method_list,\n",
    "               'candidate': candidate_name_list,\n",
    "               'candidate_email': candidate_email_list,\n",
    "               'candidate_topics': candidate_topic_list,\n",
    "               'candidate_methods': candidate_method_list,\n",
    "               'itimized_score_topics_methods_history': score_all_list,\n",
    "               'total_score': score_total_list}\n",
    "               #'scoring (topics, methods, history)': match_scoring_list}\n",
    "    #print(results)\n",
    "\n",
    "    matching_df = pd.DataFrame(data=results)\n",
    "\n",
    "    #unique_topcs_methods(reviewer_method_list, reviewer_topic_list)\n",
    "    unique_topcs_methods(results[\"candidate_topics\"], results[\"reviewer_topics\"])\n",
    "    \n",
    "    # sort to make picking the top pairs (based on score) easier\n",
    "\n",
    "    #matching_df = matching_df.sort_values(by=['candidate', 'scoring (total)'], ascending=[True, False])\n",
    "    matching_df = matching_df.sort_values(by=['total_score'], ascending=[False])\n",
    "\n",
    "    return matching_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidate-reviewer matching based on 1) topics, 2) methodology \n",
      "                  and 3) the recent review history of the possible reviewers.\n",
      "\n",
      "\n",
      "                  NOTE: By default, it is assumed that the last four columns of\n",
      "                  the reviewer's CSV file should contains the history of the\n",
      "                  reviews last four sessions (e.g. 2019S; 2019F; 2020S; 2020F). \n",
      "                  If this is not the case, please change the following line of\n",
      "                  code to reflect how many columns to use:\n",
      "                  'reviewer_history = list(reviewers_data.iloc[:,-4:])'.\n",
      "\n",
      "Total reviewers: 150; Total Candidates: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Candidate Name</th>\n",
       "      <th>Itimized score [topics, methods, reviewer's history]</th>\n",
       "      <th>total_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Acevedo, Orlando</td>\n",
       "      <td>Bobby Plascencia</td>\n",
       "      <td>[0.000, 0.500, 1.000]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lin, Yu-Shan</td>\n",
       "      <td>Bobby Plascencia</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Luber, Sandra</td>\n",
       "      <td>Bobby Plascencia</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wolf, Antje</td>\n",
       "      <td>Danuta Voegele</td>\n",
       "      <td>[1.000, 0.000, 1.000]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Acevedo, Orlando</td>\n",
       "      <td>Danuta Voegele</td>\n",
       "      <td>[0.000, 0.500, 1.000]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lin, Yu-Shan</td>\n",
       "      <td>Danuta Voegele</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sherer, Edward</td>\n",
       "      <td>Devon Cyr</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lexa, Katrina</td>\n",
       "      <td>Devon Cyr</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Loverde, Sharon M.</td>\n",
       "      <td>Devon Cyr</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May, Eric</td>\n",
       "      <td>Frank Hellickson</td>\n",
       "      <td>[1.000, 0.000, 1.000]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lexa, Katrina</td>\n",
       "      <td>Frank Hellickson</td>\n",
       "      <td>[0.000, 0.500, 1.000]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Loverde, Sharon M.</td>\n",
       "      <td>Frank Hellickson</td>\n",
       "      <td>[0.000, 0.500, 1.000]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>May, Eric</td>\n",
       "      <td>Hillary Hofman</td>\n",
       "      <td>[1.000, 0.000, 1.000]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Krämer, Andreas</td>\n",
       "      <td>Hillary Hofman</td>\n",
       "      <td>[0.000, 0.500, 1.000]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Loverde, Sharon M.</td>\n",
       "      <td>Hillary Hofman</td>\n",
       "      <td>[0.000, 0.500, 1.000]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wolf, Antje</td>\n",
       "      <td>Marica Bross</td>\n",
       "      <td>[1.000, 0.500, 1.000]</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acevedo, Orlando</td>\n",
       "      <td>Marica Bross</td>\n",
       "      <td>[0.000, 0.500, 1.000]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Krämer, Andreas</td>\n",
       "      <td>Marica Bross</td>\n",
       "      <td>[0.000, 0.500, 1.000]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Luber, Sandra</td>\n",
       "      <td>Rosita Cornejo</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lopez, Steven</td>\n",
       "      <td>Rosita Cornejo</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Krämer, Andreas</td>\n",
       "      <td>Rosita Cornejo</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>May, Eric</td>\n",
       "      <td>Shana Galey</td>\n",
       "      <td>[1.000, 0.000, 1.000]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wolf, Antje</td>\n",
       "      <td>Shana Galey</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lin, Yu-Shan</td>\n",
       "      <td>Shana Galey</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sherer, Edward</td>\n",
       "      <td>Tiffiny Bradfield</td>\n",
       "      <td>[0.000, 0.500, 1.000]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lexa, Katrina</td>\n",
       "      <td>Tiffiny Bradfield</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lopez, Steven</td>\n",
       "      <td>Tiffiny Bradfield</td>\n",
       "      <td>[0.000, 0.000, 1.000]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sherer, Edward</td>\n",
       "      <td>Virgil Lebel</td>\n",
       "      <td>[0.000, 1.000, 1.000]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lopez, Steven</td>\n",
       "      <td>Virgil Lebel</td>\n",
       "      <td>[0.000, 0.500, 1.000]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Luber, Sandra</td>\n",
       "      <td>Virgil Lebel</td>\n",
       "      <td>[0.000, 0.500, 1.000]</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Reviewer Name     Candidate Name  \\\n",
       "14    Acevedo, Orlando   Bobby Plascencia   \n",
       "19        Lin, Yu-Shan   Bobby Plascencia   \n",
       "24       Luber, Sandra   Bobby Plascencia   \n",
       "4          Wolf, Antje     Danuta Voegele   \n",
       "15    Acevedo, Orlando     Danuta Voegele   \n",
       "20        Lin, Yu-Shan     Danuta Voegele   \n",
       "17      Sherer, Edward          Devon Cyr   \n",
       "22       Lexa, Katrina          Devon Cyr   \n",
       "26  Loverde, Sharon M.          Devon Cyr   \n",
       "1            May, Eric   Frank Hellickson   \n",
       "6        Lexa, Katrina   Frank Hellickson   \n",
       "11  Loverde, Sharon M.   Frank Hellickson   \n",
       "3            May, Eric     Hillary Hofman   \n",
       "8      Krämer, Andreas     Hillary Hofman   \n",
       "13  Loverde, Sharon M.     Hillary Hofman   \n",
       "0          Wolf, Antje       Marica Bross   \n",
       "9     Acevedo, Orlando       Marica Bross   \n",
       "12     Krämer, Andreas       Marica Bross   \n",
       "25       Luber, Sandra     Rosita Cornejo   \n",
       "27       Lopez, Steven     Rosita Cornejo   \n",
       "29     Krämer, Andreas     Rosita Cornejo   \n",
       "5            May, Eric        Shana Galey   \n",
       "18         Wolf, Antje        Shana Galey   \n",
       "21        Lin, Yu-Shan        Shana Galey   \n",
       "16      Sherer, Edward  Tiffiny Bradfield   \n",
       "23       Lexa, Katrina  Tiffiny Bradfield   \n",
       "28       Lopez, Steven  Tiffiny Bradfield   \n",
       "2       Sherer, Edward       Virgil Lebel   \n",
       "7        Lopez, Steven       Virgil Lebel   \n",
       "10       Luber, Sandra       Virgil Lebel   \n",
       "\n",
       "   Itimized score [topics, methods, reviewer's history]  total_score  \n",
       "14                              [0.000, 0.500, 1.000]            1.5  \n",
       "19                              [0.000, 0.000, 1.000]            1.0  \n",
       "24                              [0.000, 0.000, 1.000]            1.0  \n",
       "4                               [1.000, 0.000, 1.000]            2.0  \n",
       "15                              [0.000, 0.500, 1.000]            1.5  \n",
       "20                              [0.000, 0.000, 1.000]            1.0  \n",
       "17                              [0.000, 0.000, 1.000]            1.0  \n",
       "22                              [0.000, 0.000, 1.000]            1.0  \n",
       "26                              [0.000, 0.000, 1.000]            1.0  \n",
       "1                               [1.000, 0.000, 1.000]            2.0  \n",
       "6                               [0.000, 0.500, 1.000]            1.5  \n",
       "11                              [0.000, 0.500, 1.000]            1.5  \n",
       "3                               [1.000, 0.000, 1.000]            2.0  \n",
       "8                               [0.000, 0.500, 1.000]            1.5  \n",
       "13                              [0.000, 0.500, 1.000]            1.5  \n",
       "0                               [1.000, 0.500, 1.000]            2.5  \n",
       "9                               [0.000, 0.500, 1.000]            1.5  \n",
       "12                              [0.000, 0.500, 1.000]            1.5  \n",
       "25                              [0.000, 0.000, 1.000]            1.0  \n",
       "27                              [0.000, 0.000, 1.000]            1.0  \n",
       "29                              [0.000, 0.000, 1.000]            1.0  \n",
       "5                               [1.000, 0.000, 1.000]            2.0  \n",
       "18                              [0.000, 0.000, 1.000]            1.0  \n",
       "21                              [0.000, 0.000, 1.000]            1.0  \n",
       "16                              [0.000, 0.500, 1.000]            1.5  \n",
       "23                              [0.000, 0.000, 1.000]            1.0  \n",
       "28                              [0.000, 0.000, 1.000]            1.0  \n",
       "2                               [0.000, 1.000, 1.000]            2.0  \n",
       "7                               [0.000, 0.500, 1.000]            1.5  \n",
       "10                              [0.000, 0.500, 1.000]            1.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ''' This programs optimizes the matching between reviewers and candidates.\n",
    "\n",
    "        Input:\n",
    "            1) candidates csv file (; seperated)\n",
    "            2) reviewers csv file (; seperated)\n",
    "        Output:\n",
    "            1) CSV formatted file of matchings (; seperated), including itimized\n",
    "            and total matching scores.\n",
    "            2) prints to screen the suggested best matchings\n",
    "\n",
    "        Structure of csv files:\n",
    "            candidates:\n",
    "                Name;Gender;Email;Methods;Topics\n",
    "            reviewers:\n",
    "                Name;Gender;Email;Methods;Topics;2019S;2019F;2020S;2020F;20??X...\n",
    "\n",
    "        Methods and Topics can be a several entries seperated by a comma.\n",
    "\n",
    "        For the reviewers, it is assumed that the last 4 columns are the histories of their reviews.\n",
    "            If they have reviewed, then the word 'reviewed' must be provided in the cell.\n",
    "\n",
    "        An example header and row for the reviewers csv file would be:\n",
    "            Name;Gender;Email;Methods;Topics;2019S;2019F;2020S;2020F\n",
    "            Smith; F; f.smith@fakeemail.com; QM, MD, Python; Protein, DNA; No; No; Yes; No\n",
    "\n",
    "        Limitations:\n",
    "            1. Each candidate is assigned 3 reviewers.\n",
    "            2. Each reviewer is assigned 3 candidates.\n",
    "            3. Only the last four history entries of the reviewer are considered in the score\n",
    "\n",
    "        Authors:\n",
    "        Daniel Jiang, Robert Bitterling and Karl N. Kirschner*\n",
    "\n",
    "            University of Applied Sciences Bonn-Rhein-Sieg\n",
    "            Grantham-Allee 20\n",
    "            53757 Sankt Augustin - Germany\n",
    "\n",
    "        Contact Information:\n",
    "            Email: k.n.kirschner@gmail.com\n",
    "    '''\n",
    "\n",
    "    # TODO: add variables for number of reviews to be done\n",
    "    # TODO: command line help information\n",
    " \n",
    "    while True:\n",
    "        try:\n",
    "            reviewers_data = None\n",
    "            #reviewers_data = pd.read_csv('CCG_Judge_List_working.csv', sep=';')\n",
    "            reviewers_data = pd.read_csv('CCG_Judge_List.csv', sep=';')\n",
    "            candidates_data = pd.read_csv('candidates_data.csv', sep=';')\n",
    "        except FileNotFoundError:\n",
    "            print('Input file(s) for reviewer or candidates was not found.')\n",
    "        else:\n",
    "            print(\"\"\"Computing best candidate-reviewer matching based on 1) topics, 2) methodology \n",
    "                  and 3) the recent review history of the possible reviewers.\n",
    "\n",
    "\n",
    "                  NOTE: By default, it is assumed that the last four columns of\n",
    "                  the reviewer's CSV file should contains the history of the\n",
    "                  reviews last four sessions (e.g. 2019S; 2019F; 2020S; 2020F). \n",
    "                  If this is not the case, please change the following line of\n",
    "                  code to reflect how many columns to use:\n",
    "                  'reviewer_history = list(reviewers_data.iloc[:,-4:])'.\\n\"\"\")\n",
    "            reviewer_history = list(reviewers_data.iloc[:,-4:])\n",
    "            \n",
    "            print(f'Total reviewers: {len(reviewers_data)}; Total Candidates: {len(candidates_data)}')\n",
    "\n",
    "            matchings = perform_matching(reviewers=reviewers_data, candidates=candidates_data,\n",
    "                                         reviewer_history=reviewer_history)\n",
    "\n",
    "            top_matches = filter_top(candidates=candidates_data, matching_df=matchings)\n",
    "            display(top_matches)\n",
    "\n",
    "            matchings.to_csv('matching_results.csv', sep=';', index=False)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
