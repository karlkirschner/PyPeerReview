{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data_point: float=None, data_list: list=None) -> float:\n",
    "    ''' Normalize the data to be within the rang of 0.0-1.0\n",
    "        Round answer to 2 digits\n",
    "    '''\n",
    "    \n",
    "    if not isinstance(data_point, (int, float)):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': Data point/value was not passed.\")\n",
    "    elif not isinstance(data_list, (list)):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': Data list of values was not passed.\")\n",
    "    else:\n",
    "        #return round( (data_point-min(data_list)) / (max(data_list)-min(data_list)), 2)\n",
    "        return format((data_point-min(data_list)) / (max(data_list)-min(data_list)), '0.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_topcs_methods(methods_list: list=None, topics_list: list=None):\n",
    "    \n",
    "    ### Try to collect all unique entries for methods and topics from reviewers\n",
    "    #print(f'All possible topics: {set(reviewer_topic_list)}')\n",
    "    \n",
    "    methods = []\n",
    "    #methods = set(methods_list)\n",
    "    uniq_methods = ', '.join(set(methods_list)).split(', ') \n",
    "    #print(f'All possible methods: {set(uniq_methods)}\\n')\n",
    "\n",
    "    topics = []\n",
    "    #topics = set(topics_list)\n",
    "    uniq_topics = ', '.join(set(topics_list)).split(', ') \n",
    "    #print(f'All possible topics: {set(uniq_topics)}\\n')\n",
    "\n",
    "    counter=0\n",
    "    #print(topics_list)\n",
    "    for topic in uniq_topics:\n",
    "        for t in topics_list:\n",
    "            if topic == t:\n",
    "                counter += 1\n",
    "        #print(f'{topic}: {counter}')\n",
    "    revi_methods = pd.DataFrame(data={'Methods': sorted(list(set(uniq_methods)))})\n",
    "    revi_methods.to_csv('reviewer_methods.csv', sep=';', index=False)\n",
    "    revi_topics = pd.DataFrame(data={'Methods': sorted(list(set(uniq_topics)))})\n",
    "    revi_topics.to_csv('reviewer_topics.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_top(candidates: pd.DataFrame=None, matching_df: pd.DataFrame=None) -> pd.DataFrame:\n",
    "    ''' Select the top 3 matchings for each candidate and reviewer and return the results.'''\n",
    "    \n",
    "    if not isinstance(candidates, pd.core.frame.DataFrame) or not isinstance(matching_df, pd.core.frame.DataFrame):\n",
    "        sys.exit(f\"Function '{filter_top.__name__}': Either 'candidates' or 'matching_df' \"\n",
    "                  \"was not passed as a Pandas dataframe.\")\n",
    "\n",
    "    reviewer_collector = {}\n",
    "    candidate_collector = {}\n",
    "    perfect_score_list = []\n",
    "\n",
    "    ## TODO: check to see if I can remove the second condition below (and...)\n",
    "\n",
    "    ## len(candidates) is the same as candidates.shape[0]\n",
    "\n",
    "    ## assign starting value of zero\n",
    "    for candidate in candidates.itertuples():\n",
    "        if not candidate[1] in candidate_collector and len(candidate_collector) < len(candidates):\n",
    "            candidate_collector[candidate[1]] = 0\n",
    "            #print(candidate_collector)\n",
    "\n",
    "    # key part: must operate on matching_df that has been sorted by total_score, and then limit it\n",
    "    for reviewer in matching_df.itertuples():\n",
    "        if not reviewer[1] in reviewer_collector and len(reviewer_collector) < len(candidates):\n",
    "            reviewer_collector[reviewer[1]] = 0\n",
    "            #print(reviewer_collector)\n",
    "\n",
    "    for index, matching_pair in matching_df.iterrows():\n",
    "        revi = matching_pair['reviewer']\n",
    "        revi_email = matching_pair['reviewer_email']\n",
    "        revi_topics = matching_pair['reviewer_topics']\n",
    "        revi_methods = matching_pair['reviewer_methods']\n",
    "        candi = matching_pair['candidate']\n",
    "        candi_email = matching_pair['candidate_email']\n",
    "        candi_topics = matching_pair['candidate_topics']\n",
    "        candi_methods = matching_pair['candidate_methods']\n",
    "        itimized_score = matching_pair['itimized_score_topics_methods_history']\n",
    "        total_score = matching_pair['total_score']\n",
    "        \n",
    "        if revi in reviewer_collector and candi in candidate_collector \\\n",
    "                                      and reviewer_collector[revi] != 3 \\\n",
    "                                      and candidate_collector[candi] != 3:\n",
    "            perfect_score_list.append((revi, candi, itimized_score, total_score))\n",
    "            reviewer_collector[revi] += 1\n",
    "            candidate_collector[candi] += 1\n",
    "            #print(reviewer_collector)\n",
    "\n",
    "    final_df = pd.DataFrame(data={'Reviewer Name': [i[0] for i in perfect_score_list],\n",
    "                                  'Candidate Name': [i[1] for i in perfect_score_list],\n",
    "                                  \"Itimized score [topics, methods, reviewer's history]\": [i[2] for i in perfect_score_list],\n",
    "                                  'total_score': [i[3] for i in perfect_score_list]})\n",
    "\n",
    "    # Could sort by \"Reviewer Name\" or \"Candidate Name\"\n",
    "    final_df = final_df.sort_values(by=['Candidate Name', 'total_score'], ascending=[True, False])\n",
    "    #final_df = final_df.sort_values(by=['total_score', 'Candidate Name'], ascending=[False, False])\n",
    "\n",
    "    #print(perfect_score_list)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(reviewer: pd.Series=None, candidate: pd.Series=None, reviewer_history: list=None) -> int:\n",
    "    ''' Score the matching between reviewer and candidate based on:\n",
    "        1) topics,\n",
    "        2) methods, and\n",
    "        3) history of recent reviews done by reviewer.\n",
    "    '''\n",
    "\n",
    "    if not isinstance(reviewer, pd.core.series.Series) or not isinstance(candidate, pd.core.series.Series):\n",
    "        sys.exit(f\"Function '{scoring.__name__}': Either 'reviewer' or 'candidate' \"\n",
    "                  \"was not passed as a Pandas dataframe.\")\n",
    "    elif not isinstance(reviewer_history, list):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': History of reviewers' reviews not passed.\")\n",
    "\n",
    "    score_topics = 0\n",
    "    score_methods = 0\n",
    "    score_history = 0\n",
    "    score_total = 0\n",
    "\n",
    "    reviewer_topics = reviewer['Topics'].split(sep=', ')\n",
    "    candidate_topics = candidate['Topics'].split(sep=', ')\n",
    "    reviewer_methods = reviewer['Methods'].split(sep=', ')\n",
    "    candidate_methods = candidate['Methods'].split(sep=', ')\n",
    "    \n",
    "    for topic in reviewer_topics:\n",
    "        if topic.lower() in candidate_topics:\n",
    "            score_topics += 1\n",
    "\n",
    "    for methodology in reviewer_methods:\n",
    "        if methodology in candidate_methods:\n",
    "            score_methods += 1\n",
    "\n",
    "    reviewer_history_reversed = list(reversed(reviewer_history))\n",
    "    \n",
    "    for session in reviewer_history_reversed:\n",
    "        #print(session, reviewer_history_reversed.index(session),\n",
    "        #      reviewer_history_reversed.index(session)+1, (reviewer_history_reversed.index(session)+1)/4)\n",
    "        factor = (reviewer_history_reversed.index(session)+1)/len(reviewer_history_reversed)\n",
    "        if str(reviewer[session]).lower() != 'reviewed':\n",
    "             score_history += (1 - factor)\n",
    "             #print(session, factor, score_history)\n",
    "\n",
    "    return score_topics, score_methods, score_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function annotation\n",
    "def perform_matching(reviewers: pd.DataFrame=None, candidates: pd.DataFrame=None,\n",
    "                     reviewer_history: list=None) -> pd.DataFrame:\n",
    "    '''\n",
    "    1. Creates lists from dataframes\n",
    "    2. Calls scoring function\n",
    "    3. Sorts the top 3 scoreed matches for each pairing\n",
    "    '''\n",
    "\n",
    "    if not isinstance(reviewers, pd.core.frame.DataFrame) or not isinstance(candidates, pd.core.frame.DataFrame):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': Either 'reviewers' or 'candidates' \"\n",
    "                 \"was not passed as a Pandas dataframe.\")\n",
    "    elif not isinstance(reviewer_history, list):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': History of reviewers' reviews not passed.\")\n",
    "\n",
    "    reviewer_name_list = []\n",
    "    reviewer_email_list = []\n",
    "    reviewer_topic_list = []\n",
    "    reviewer_method_list = []\n",
    "\n",
    "    candidate_name_list = []\n",
    "    candidate_email_list = []\n",
    "    candidate_topic_list = []\n",
    "    candidate_method_list = []\n",
    "\n",
    "    match_scoring_list = []\n",
    "\n",
    "    score_all_list = []\n",
    "    score_total_list = []\n",
    "\n",
    "    # Basic idea here is that each of the X reviewers is listed with each of the Y candidate, and then scored\n",
    "\n",
    "    for i in range(len(reviewers)):  # number_reviewers_rows; reviewers.shape[0]\n",
    "        for j in range(len(candidates)):  # number_candidates_rows; candidates.shape[0]\n",
    "            reviewer_name_list.append(reviewers.loc[i].Name)\n",
    "            reviewer_email_list.append(reviewers.loc[i].Email)\n",
    "            reviewer_topic_list.append(reviewers.loc[i].Topics)\n",
    "            reviewer_method_list.append(reviewers.loc[i].Methods)\n",
    "\n",
    "            candidate_name_list.append(candidates.loc[j].Name)\n",
    "            candidate_email_list.append(candidates.loc[j].Email)\n",
    "            candidate_topic_list.append(candidates.loc[j].Topics)\n",
    "            candidate_method_list.append(candidates.loc[j].Methods)\n",
    "\n",
    "            #print(reviewer_topic_list)\n",
    "            ## scoring is done here\n",
    "            score_topics, score_methods, score_history = scoring(reviewer=reviewers.loc[i], candidate=candidates.loc[j],\n",
    "                                             reviewer_history=reviewer_history)\n",
    "            score_all = [score_topics, score_methods, score_history]\n",
    "            score_all_list.append(score_all)\n",
    "\n",
    "            score_total = score_topics + score_methods + score_history\n",
    "            score_total_list.append(score_total)\n",
    "            #match_scoring_list.append(scoring(reviewer=reviewers.loc[i], candidate=candidates.loc[j]))\n",
    "    #print(score_all_list)\n",
    "    ##############\n",
    "    ## Normalizing attempt (history = 2)\n",
    "    top = []\n",
    "    sub = []\n",
    "    hist = []\n",
    "    \n",
    "    for sublist in (score_all_list):\n",
    "        top.append(sublist[0])\n",
    "        sub.append(sublist[1])\n",
    "        hist.append(sublist[2])\n",
    "    score_topic_normalized = [normalize(x, top) for x in top]\n",
    "    score_subject_normalized = [normalize(x, sub) for x in sub]\n",
    "    score_history_normalized = [normalize(x, hist) for x in hist]\n",
    "\n",
    "    score_all_list =[]\n",
    "    score_all_list.extend([list(a) for a in zip(score_topic_normalized,\n",
    "                                                       score_subject_normalized,\n",
    "                                                       score_history_normalized)])\n",
    "    #print(score_all_list)\n",
    "\n",
    "    score_total_list =[]\n",
    "    score_total_list =[float(a)+float(b)+float(c) for a,b,c in zip(score_topic_normalized,\n",
    "                                                       score_subject_normalized,\n",
    "                                                       score_history_normalized)]\n",
    "    #matching_df['itimized_score_topics_methods_history'] = hist_normalized\n",
    "    ##############\n",
    "    \n",
    "    results = {'reviewer': reviewer_name_list,\n",
    "               'reviewer_email': reviewer_email_list,\n",
    "               'reviewer_topics': reviewer_topic_list,\n",
    "               'reviewer_methods': reviewer_method_list,\n",
    "               'candidate': candidate_name_list,\n",
    "               'candidate_email': candidate_email_list,\n",
    "               'candidate_topics': candidate_topic_list,\n",
    "               'candidate_methods': candidate_method_list,\n",
    "               'itimized_score_topics_methods_history': score_all_list,\n",
    "               'total_score': score_total_list}\n",
    "               #'scoring (topics, methods, history)': match_scoring_list}\n",
    "    #print(results)\n",
    "\n",
    "    matching_df = pd.DataFrame(data=results)\n",
    "\n",
    "    #unique_topcs_methods(reviewer_method_list, reviewer_topic_list)\n",
    "    unique_topcs_methods(results[\"candidate_topics\"], results[\"reviewer_topics\"])\n",
    "    \n",
    "    # sort to make picking the top pairs (based on score) easier\n",
    "\n",
    "    #matching_df = matching_df.sort_values(by=['candidate', 'scoring (total)'], ascending=[True, False])\n",
    "    matching_df = matching_df.sort_values(by=['total_score'], ascending=[False])\n",
    "\n",
    "    return matching_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ''' This programs optimizes the matching between reviewers and candidates.\n",
    "\n",
    "        Input:\n",
    "            1) candidates csv file (; seperated)\n",
    "            2) reviewers csv file (; seperated)\n",
    "        Output:\n",
    "            1) CSV formatted file of matchings (; seperated), including itimized\n",
    "            and total matching scores.\n",
    "            2) prints to screen the suggested best matchings\n",
    "\n",
    "        Structure of csv files:\n",
    "            candidates:\n",
    "                Name;Gender;Email;Methods;Topics\n",
    "            reviewers:\n",
    "                Name;Gender;Email;Methods;Topics;2019S;2019F;2020S;2020F;20??X...\n",
    "\n",
    "        Methods and Topics can be a several entries seperated by a comma.\n",
    "\n",
    "        For the reviewers, it is assumed that the last 4 columns are the histories of their reviews.\n",
    "            If they have reviewed, then the word 'reviewed' must be provided in the cell.\n",
    "\n",
    "        An example header and row for the reviewers csv file would be:\n",
    "            Name;Gender;Email;Methods;Topics;2019S;2019F;2020S;2020F\n",
    "            Smith; F; f.smith@fakeemail.com; QM, MD, Python; Protein, DNA; No; No; Yes; No\n",
    "\n",
    "        Limitations:\n",
    "            1. Each candidate is assigned 3 reviewers.\n",
    "            2. Each reviewer is assigned 3 candidates.\n",
    "            3. Only the last four history entries of the reviewer are considered in the score\n",
    "\n",
    "        Authors:\n",
    "        Daniel Jiang, Robert Bitterling and Karl N. Kirschner*\n",
    "\n",
    "            University of Applied Sciences Bonn-Rhein-Sieg\n",
    "            Grantham-Allee 20\n",
    "            53757 Sankt Augustin - Germany\n",
    "\n",
    "        Contact Information:\n",
    "            Email: k.n.kirschner@gmail.com\n",
    "    '''\n",
    "\n",
    "    # TODO: add variables for number of reviews to be done\n",
    "    # TODO: command line help information\n",
    " \n",
    "    while True:\n",
    "        try:\n",
    "            reviewers_data = None\n",
    "            #reviewers_data = pd.read_csv('CCG_Judge_List_working.csv', sep=';')\n",
    "            reviewers_data = pd.read_csv('CCG_Judge_List.csv', sep=';')\n",
    "            candidates_data = pd.read_csv('candidates_data.csv', sep=';')\n",
    "        except FileNotFoundError:\n",
    "            print('Input file(s) for reviewer or candidates was not found.')\n",
    "        else:\n",
    "            print(\"\"\"Computing best candidate-reviewer matching based on 1) topics, 2) methodology \n",
    "                  and 3) the recent review history of the possible reviewers.\n",
    "\n",
    "\n",
    "                  NOTE: By default, it is assumed that the last four columns of\n",
    "                  the reviewer's CSV file should contains the history of the\n",
    "                  reviews last four sessions (e.g. 2019S; 2019F; 2020S; 2020F). \n",
    "                  If this is not the case, please change the following line of\n",
    "                  code to reflect how many columns to use:\n",
    "                  'reviewer_history = list(reviewers_data.iloc[:,-4:])'.\\n\"\"\")\n",
    "            reviewer_history = list(reviewers_data.iloc[:,-4:])\n",
    "            \n",
    "            print(f'Total reviewers: {len(reviewers_data)}; Total Candidates: {len(candidates_data)}')\n",
    "\n",
    "            matchings = perform_matching(reviewers=reviewers_data, candidates=candidates_data,\n",
    "                                         reviewer_history=reviewer_history)\n",
    "\n",
    "            top_matches = filter_top(candidates=candidates_data, matching_df=matchings)\n",
    "            display(top_matches)\n",
    "\n",
    "            matchings.to_csv('matching_results.csv', sep=';', index=False)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
