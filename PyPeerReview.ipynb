{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data_point: float, data_list: list) -> float:\n",
    "    ''' Normalize the data to be within the rang of 0.0-1.0\n",
    "        Round answer to 2 digits\n",
    "    '''\n",
    "    if not isinstance(data_point, (int, float)):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': Data point/value was not passed.\")\n",
    "    elif not isinstance(data_list, (list)):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': Data list of values was not passed.\")\n",
    "    else:\n",
    "        return format((data_point-min(data_list)) / (max(data_list)-min(data_list)), '0.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_topcs_methods(methods_list: list, topics_list: list):\n",
    "    \n",
    "    ### Try to collect all unique entries for methods and topics from reviewers\n",
    "    #print(f'All possible topics: {set(reviewer_topic_list)}')\n",
    "    \n",
    "    methods = []\n",
    "    #methods = set(methods_list)\n",
    "    uniq_methods = ', '.join(set(methods_list)).split(', ') \n",
    "    #print(f'All possible methods: {set(uniq_methods)}\\n')\n",
    "\n",
    "    topics = []\n",
    "    #topics = set(topics_list)\n",
    "    uniq_topics = ', '.join(set(topics_list)).split(', ') \n",
    "    #print(f'All possible topics: {set(uniq_topics)}\\n')\n",
    "\n",
    "    counter=0\n",
    "    #print(topics_list)\n",
    "    for topic in uniq_topics:\n",
    "        for t in topics_list:\n",
    "            if topic == t:\n",
    "                counter += 1\n",
    "        #print(f'{topic}: {counter}')\n",
    "    revi_methods = pd.DataFrame(data={'Methods': sorted(list(set(uniq_methods)))})\n",
    "    revi_methods.to_csv('reviewer_methods.csv', sep=';', index=False)\n",
    "    revi_topics = pd.DataFrame(data={'Methods': sorted(list(set(uniq_topics)))})\n",
    "    revi_topics.to_csv('reviewer_topics.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_top(entrants: pd.DataFrame, matching_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ''' Select the top 3 matchings for each candidate and reviewer and return the results.'''\n",
    "    \n",
    "    if not isinstance(entrants, pd.core.frame.DataFrame) or not isinstance(matching_df, pd.core.frame.DataFrame):\n",
    "        sys.exit(f\"Function '{filter_top.__name__}': Either 'entrants' or 'matching_df' \"\n",
    "                  \"was not passed as a Pandas dataframe.\")\n",
    "\n",
    "    reviewer_collector = {}\n",
    "    candidate_collector = {}\n",
    "    perfect_score_list = []\n",
    "\n",
    "    ## TODO: check to see if I can remove the second condition below (and...)\n",
    "\n",
    "    ## len(entrants) is the same as entrants.shape[0]\n",
    "\n",
    "    ## assign starting value of zero\n",
    "    for candidate in entrants.itertuples():\n",
    "        if not candidate[1] in candidate_collector and len(candidate_collector) < len(entrants):\n",
    "            candidate_collector[candidate[1]] = 0\n",
    "            #print(candidate_collector)\n",
    "\n",
    "    # key part: must operate on matching_df that has been sorted by total_score, and then limit it\n",
    "    for reviewer in matching_df.itertuples():\n",
    "        if not reviewer[1] in reviewer_collector and len(reviewer_collector) < len(entrants):\n",
    "            reviewer_collector[reviewer[1]] = 0\n",
    "            #print(reviewer_collector)\n",
    "\n",
    "    for index, matching_pair in matching_df.iterrows():\n",
    "        revi = matching_pair['reviewer']\n",
    "        revi_email = matching_pair['reviewer_email']\n",
    "        revi_topics = matching_pair['reviewer_topics']\n",
    "        revi_methods = matching_pair['reviewer_methods']\n",
    "        candi = matching_pair['candidate']\n",
    "        candi_email = matching_pair['candidate_email']\n",
    "        candi_topics = matching_pair['candidate_topics']\n",
    "        candi_methods = matching_pair['candidate_methods']\n",
    "        itimized_score = matching_pair['itimized_score_topics_methods_history']\n",
    "        total_score = matching_pair['total_score']\n",
    "        \n",
    "        if revi in reviewer_collector and candi in candidate_collector \\\n",
    "                                      and reviewer_collector[revi] != 3 \\\n",
    "                                      and candidate_collector[candi] != 3:\n",
    "            perfect_score_list.append((revi, candi, itimized_score, total_score))\n",
    "            reviewer_collector[revi] += 1\n",
    "            candidate_collector[candi] += 1\n",
    "            #print(reviewer_collector)\n",
    "\n",
    "    final_df = pd.DataFrame(data={'Reviewer Name': [i[0] for i in perfect_score_list],\n",
    "                                  'Candidate Name': [i[1] for i in perfect_score_list],\n",
    "                                  \"Itimized score [topics, methods, reviewer's history]\": [i[2] for i in perfect_score_list],\n",
    "                                  'total_score': [i[3] for i in perfect_score_list]})\n",
    "\n",
    "    # Could sort by \"Reviewer Name\" or \"Candidate Name\"\n",
    "    final_df = final_df.sort_values(by=['Candidate Name', 'total_score'], ascending=[True, False])\n",
    "    #final_df = final_df.sort_values(by=['total_score', 'Candidate Name'], ascending=[False, False])\n",
    "\n",
    "    #print(perfect_score_list)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(reviewer: pd.Series, candidate: pd.Series, reviewer_history: list) -> int:\n",
    "    ''' Score the matching between reviewer and candidate based on:\n",
    "        1) topics,\n",
    "        2) methods, and\n",
    "        3) history of recent reviews done by reviewer.\n",
    "    '''\n",
    "\n",
    "    if not isinstance(reviewer, pd.core.series.Series) or not isinstance(candidate, pd.core.series.Series):\n",
    "        sys.exit(f\"Function '{scoring.__name__}': Either 'reviewer' or 'candidate' \"\n",
    "                  \"was not passed as a Pandas dataframe.\")\n",
    "    elif not isinstance(reviewer_history, list):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': History of reviewers' reviews not passed.\")\n",
    "\n",
    "    score_topics = 0\n",
    "    score_methods = 0\n",
    "    score_history = 0\n",
    "    score_total = 0\n",
    "\n",
    "    reviewer_topics = reviewer['Topics'].split(sep=', ')\n",
    "    candidate_topics = candidate['Topics'].split(sep=', ')\n",
    "    reviewer_methods = reviewer['Methods'].split(sep=', ')\n",
    "    candidate_methods = candidate['Methods'].split(sep=', ')\n",
    "    \n",
    "    for topic in reviewer_topics:\n",
    "        if topic.lower() in candidate_topics:\n",
    "            score_topics += 1\n",
    "\n",
    "    for methodology in reviewer_methods:\n",
    "        if methodology in candidate_methods:\n",
    "            score_methods += 1\n",
    "\n",
    "    reviewer_history_reversed = list(reversed(reviewer_history))\n",
    "    \n",
    "    for session in reviewer_history_reversed:\n",
    "        #print(session, reviewer_history_reversed.index(session),\n",
    "        #      reviewer_history_reversed.index(session)+1, (reviewer_history_reversed.index(session)+1)/4)\n",
    "        factor = (reviewer_history_reversed.index(session)+1)/len(reviewer_history_reversed)\n",
    "        if str(reviewer[session]).lower() != 'reviewed':\n",
    "             score_history += (1 - factor)\n",
    "             #print(session, factor, score_history)\n",
    "\n",
    "    return score_topics, score_methods, score_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function annotation\n",
    "def perform_matching(reviewers: pd.DataFrame, entrants: pd.DataFrame,\n",
    "                     reviewer_history: list) -> pd.DataFrame:\n",
    "    '''\n",
    "    1. Creates lists from dataframes\n",
    "    2. Calls scoring function\n",
    "    3. Sorts the top 3 scoreed matches for each pairing\n",
    "    '''\n",
    "\n",
    "    if not isinstance(reviewers, pd.core.frame.DataFrame) or not isinstance(entrants, pd.core.frame.DataFrame):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': Either 'reviewers' or 'entrants' \"\n",
    "                 \"was not passed as a Pandas dataframe.\")\n",
    "    elif not isinstance(reviewer_history, list):\n",
    "        sys.exit(f\"Function '{perform_matching.__name__}': History of reviewers' reviews not passed.\")\n",
    "\n",
    "    reviewer_name_list = []\n",
    "    reviewer_email_list = []\n",
    "    reviewer_topic_list = []\n",
    "    reviewer_method_list = []\n",
    "\n",
    "    candidate_name_list = []\n",
    "    candidate_email_list = []\n",
    "    candidate_topic_list = []\n",
    "    candidate_method_list = []\n",
    "\n",
    "    match_scoring_list = []\n",
    "\n",
    "    score_all_list = []\n",
    "    score_total_list = []\n",
    "\n",
    "    # Basic idea here is that each of the X reviewers is listed with each of the Y candidate, and then scored\n",
    "\n",
    "    for i in range(len(reviewers)):  # number_reviewers_rows; reviewers.shape[0]\n",
    "        for j in range(len(entrants)):  # number_entrants_rows; entrants.shape[0]\n",
    "            reviewer_name_list.append(reviewers.loc[i].Name)\n",
    "            reviewer_email_list.append(reviewers.loc[i].Email)\n",
    "            reviewer_topic_list.append(reviewers.loc[i].Topics)\n",
    "            reviewer_method_list.append(reviewers.loc[i].Methods)\n",
    "\n",
    "            candidate_name_list.append(entrants.loc[j].Name)\n",
    "            candidate_email_list.append(entrants.loc[j].Email)\n",
    "            candidate_topic_list.append(entrants.loc[j].Topics)\n",
    "            candidate_method_list.append(entrants.loc[j].Methods)\n",
    "\n",
    "            #print(reviewer_topic_list)\n",
    "            ## scoring is done here\n",
    "            score_topics, score_methods, score_history = scoring(reviewer=reviewers.loc[i], candidate=entrants.loc[j],\n",
    "                                             reviewer_history=reviewer_history)\n",
    "            score_all = [score_topics, score_methods, score_history]\n",
    "            score_all_list.append(score_all)\n",
    "\n",
    "            score_total = score_topics + score_methods + score_history\n",
    "            score_total_list.append(score_total)\n",
    "            #match_scoring_list.append(scoring(reviewer=reviewers.loc[i], candidate=entrants.loc[j]))\n",
    "    #print(score_all_list)\n",
    "    ##############\n",
    "    ## Normalizing attempt (history = 2)\n",
    "    top = []\n",
    "    sub = []\n",
    "    hist = []\n",
    "    \n",
    "    for sublist in (score_all_list):\n",
    "        top.append(sublist[0])\n",
    "        sub.append(sublist[1])\n",
    "        hist.append(sublist[2])\n",
    "    score_topic_normalized = [normalize(x, top) for x in top]\n",
    "    score_subject_normalized = [normalize(x, sub) for x in sub]\n",
    "    score_history_normalized = [normalize(x, hist) for x in hist]\n",
    "\n",
    "    score_all_list =[]\n",
    "    score_all_list.extend([list(a) for a in zip(score_topic_normalized,\n",
    "                                                       score_subject_normalized,\n",
    "                                                       score_history_normalized)])\n",
    "    #print(score_all_list)\n",
    "\n",
    "    score_total_list =[]\n",
    "    score_total_list =[float(a)+float(b)+float(c) for a,b,c in zip(score_topic_normalized,\n",
    "                                                       score_subject_normalized,\n",
    "                                                       score_history_normalized)]\n",
    "    #matching_df['itimized_score_topics_methods_history'] = hist_normalized\n",
    "    ##############\n",
    "    \n",
    "    results = {'reviewer': reviewer_name_list,\n",
    "               'reviewer_email': reviewer_email_list,\n",
    "               'reviewer_topics': reviewer_topic_list,\n",
    "               'reviewer_methods': reviewer_method_list,\n",
    "               'candidate': candidate_name_list,\n",
    "               'candidate_email': candidate_email_list,\n",
    "               'candidate_topics': candidate_topic_list,\n",
    "               'candidate_methods': candidate_method_list,\n",
    "               'itimized_score_topics_methods_history': score_all_list,\n",
    "               'total_score': score_total_list}\n",
    "               #'scoring (topics, methods, history)': match_scoring_list}\n",
    "    #print(results)\n",
    "\n",
    "    matching_df = pd.DataFrame(data=results)\n",
    "\n",
    "    #unique_topcs_methods(reviewer_method_list, reviewer_topic_list)\n",
    "    unique_topcs_methods(results[\"candidate_topics\"], results[\"reviewer_topics\"])\n",
    "    \n",
    "    # sort to make picking the top pairs (based on score) easier\n",
    "\n",
    "    #matching_df = matching_df.sort_values(by=['candidate', 'scoring (total)'], ascending=[True, False])\n",
    "    matching_df = matching_df.sort_values(by=['total_score'], ascending=[False])\n",
    "\n",
    "    return matching_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best candidate-reviewer matching based on 1) topics, 2) methodology \n",
      "                  and 3) the recent review history of the possible reviewers.\n",
      "\n",
      "\n",
      "                  NOTE: By default, it is assumed that the last four columns of\n",
      "                  the reviewer's CSV file should contains the history of the\n",
      "                  reviews last four sessions (e.g. 2019S; 2019F; 2020S; 2020F). \n",
      "                  If this is not the case, please change the following line of\n",
      "                  code to reflect how many columns to use:\n",
      "                  'reviewer_history = list(reviewers_data.iloc[:,-4:])'.\n",
      "\n",
      "KNK                      Name            Email                           Methods  \\\n",
      "0     Zoowee Blubberworth  zb@fakemail.com                   Mathematics, md   \n",
      "1       Flufffy Gloomkins  fg@fakemail.com                    md, Statistics   \n",
      "2         Buritt Noseface  bn@fakemail.com                        ff, Python   \n",
      "3  Peaberry Wigglewhistle  pw@fakemail.com                bioinformatics, qm   \n",
      "4       Trashwee Sockborn  ts@fakemail.com                          ff, Java   \n",
      "5  Flapberry Fudgewhistle  ff@fakemail.com  Numerical Algorithms, Basis Sets   \n",
      "6     Gummoo Hooperbottom  gh@fakemail.com        Java, Numerical Algorithms   \n",
      "7     Humster Pottyworthy  hp@fakemail.com             Raman, bioinformatics   \n",
      "8        Bugby Doodoohill  bd@fakemail.com           Machine Learning, X-ray   \n",
      "9          Gootu Snotborn  gs@fakemail.com                        md, Python   \n",
      "\n",
      "                                 Topics  \n",
      "0                     viruses, Security  \n",
      "1             Virtual Reality, proteins  \n",
      "2              Virtual Reality, viruses  \n",
      "3              dna, methods development  \n",
      "4                         dna, proteins  \n",
      "5          viruses, methods development  \n",
      "6  methods development, Virtual Reality  \n",
      "7              dna, methods development  \n",
      "8                carbo, Virtual Reality  \n",
      "9                        carbo, viruses  \n",
      "Total reviewers: 50; Total entrants: 10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'Methods'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-05ed8843d2b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             matchings = perform_matching(reviewers=reviewers_data, entrants=entrants_data,\n\u001b[0;32m---> 68\u001b[0;31m                                          reviewer_history=reviewer_history)\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mtop_matches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_top\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentrants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentrants_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatching_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatchings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-e1d26162e007>\u001b[0m in \u001b[0;36mperform_matching\u001b[0;34m(reviewers, entrants, reviewer_history)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mreviewer_email_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviewers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mreviewer_topic_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviewers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTopics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mreviewer_method_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviewers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mcandidate_name_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentrants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas-1.0.4-py3.7-linux-x86_64.egg/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'Methods'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ''' This programs optimizes the matching between reviewers and entrants.\n",
    "\n",
    "        Input:\n",
    "            1) reviewers CSV file (; seperated)\n",
    "            2) entrants CSV file (; seperated)\n",
    "        Output:\n",
    "            1) CSV formatted file of matchings (; seperated), including itimized\n",
    "            and total matching scores.\n",
    "            2) prints to screen the suggested best matchings\n",
    "\n",
    "        Structure of CSV files:\n",
    "            entrants:\n",
    "                Name;Email;Methods;Topics\n",
    "            reviewers:\n",
    "                Name;Email;Methods;Topics;2019S;2019F;2020S;2020F;20??s...\n",
    "\n",
    "        Methods and Topics can be a several entries seperated by a comma.\n",
    "\n",
    "        For the reviewers, it is assumed that the last 4 columns are the histories of their reviews.\n",
    "            If they have reviewed, then the word 'reviewed' must be provided in the cell.\n",
    "\n",
    "        Limitations:\n",
    "            1. Each candidate is assigned 3 reviewers.\n",
    "            2. Each reviewer is assigned 3 entrants.\n",
    "            3. Only the last four history entries of the reviewer are considered in the score\n",
    "\n",
    "        Contact:\n",
    "            Daniel Jiang, Robert Bitterling and Karl N. Kirschner*\n",
    "            University of Applied Sciences Bonn-Rhein-Sieg\n",
    "            Grantham-Allee 20\n",
    "            53757 Sankt Augustin - Germany\n",
    "\n",
    "            Email: k.n.kirschner@gmail.com\n",
    "            \n",
    "        Contribution:\n",
    "            Concept: Kirschner\n",
    "            Initial coding and structure: Jiang and Bitterling\n",
    "            Final coding: Kirschner\n",
    "    '''\n",
    "\n",
    "    # TODO: add variables for number of reviews to be done\n",
    " \n",
    "    while True:\n",
    "        try:\n",
    "            reviewers_data = None\n",
    "            reviewers_data = pd.read_csv('reviewers.csv', sep=';')\n",
    "            entrants_data = pd.read_csv('entrants.csv', sep=';')\n",
    "        except FileNotFoundError:\n",
    "            print('Input files for reviewer or entrants was not found.')\n",
    "        else:\n",
    "            print(\"\"\"Computing best candidate-reviewer matching based on 1) topics, 2) methodology \n",
    "                  and 3) the recent review history of the possible reviewers.\n",
    "\n",
    "\n",
    "                  NOTE: By default, it is assumed that the last four columns of\n",
    "                  the reviewer's CSV file should contains the history of the\n",
    "                  reviews last four sessions (e.g. 2019S; 2019F; 2020S; 2020F). \n",
    "                  If this is not the case, please change the following line of\n",
    "                  code to reflect how many columns to use:\n",
    "                  'reviewer_history = list(reviewers_data.iloc[:,-4:])'.\\n\"\"\")\n",
    "            print('KNK', entrants_data)\n",
    "            reviewer_history = list(reviewers_data.iloc[:,-4:])\n",
    "\n",
    "            print(f'Total reviewers: {len(reviewers_data)}; Total entrants: {len(entrants_data)}')\n",
    "\n",
    "            matchings = perform_matching(reviewers=reviewers_data, entrants=entrants_data,\n",
    "                                         reviewer_history=reviewer_history)\n",
    "\n",
    "            top_matches = filter_top(entrants=entrants_data, matching_df=matchings)\n",
    "            display(top_matches)\n",
    "\n",
    "            matchings.to_csv('matching_results.csv', sep=';', index=False)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
